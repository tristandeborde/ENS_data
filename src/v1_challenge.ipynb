{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input, Activation, Dense, Dropout, Flatten, Lambda, LSTM, GRU\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.read_csv('../data/x_train.csv').set_index('ID')\n",
    "dfy = pd.read_csv('../data/y_train.csv').set_index('ID')\n",
    "dfx_test = pd.read_csv('../data/x_test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron_id</th>\n",
       "      <th>timestamp_0</th>\n",
       "      <th>timestamp_1</th>\n",
       "      <th>timestamp_2</th>\n",
       "      <th>timestamp_3</th>\n",
       "      <th>timestamp_4</th>\n",
       "      <th>timestamp_5</th>\n",
       "      <th>timestamp_6</th>\n",
       "      <th>timestamp_7</th>\n",
       "      <th>timestamp_8</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_40</th>\n",
       "      <th>timestamp_41</th>\n",
       "      <th>timestamp_42</th>\n",
       "      <th>timestamp_43</th>\n",
       "      <th>timestamp_44</th>\n",
       "      <th>timestamp_45</th>\n",
       "      <th>timestamp_46</th>\n",
       "      <th>timestamp_47</th>\n",
       "      <th>timestamp_48</th>\n",
       "      <th>timestamp_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28599</th>\n",
       "      <td>9456</td>\n",
       "      <td>1.501446</td>\n",
       "      <td>1.935893</td>\n",
       "      <td>2.100466</td>\n",
       "      <td>2.144410</td>\n",
       "      <td>2.259503</td>\n",
       "      <td>2.269867</td>\n",
       "      <td>2.292989</td>\n",
       "      <td>2.346420</td>\n",
       "      <td>2.724702</td>\n",
       "      <td>...</td>\n",
       "      <td>20.970412</td>\n",
       "      <td>20.984293</td>\n",
       "      <td>20.997030</td>\n",
       "      <td>21.016212</td>\n",
       "      <td>21.039446</td>\n",
       "      <td>21.044450</td>\n",
       "      <td>21.277555</td>\n",
       "      <td>21.723172</td>\n",
       "      <td>22.037007</td>\n",
       "      <td>22.061580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28600</th>\n",
       "      <td>10064</td>\n",
       "      <td>0.059309</td>\n",
       "      <td>0.116247</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.262012</td>\n",
       "      <td>0.301379</td>\n",
       "      <td>1.813054</td>\n",
       "      <td>2.068066</td>\n",
       "      <td>2.168285</td>\n",
       "      <td>2.232430</td>\n",
       "      <td>...</td>\n",
       "      <td>21.518761</td>\n",
       "      <td>22.137357</td>\n",
       "      <td>22.504569</td>\n",
       "      <td>23.102718</td>\n",
       "      <td>23.155953</td>\n",
       "      <td>23.254136</td>\n",
       "      <td>23.302653</td>\n",
       "      <td>23.480564</td>\n",
       "      <td>23.539625</td>\n",
       "      <td>23.585673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28601</th>\n",
       "      <td>10045</td>\n",
       "      <td>0.563164</td>\n",
       "      <td>1.563625</td>\n",
       "      <td>1.677879</td>\n",
       "      <td>1.881264</td>\n",
       "      <td>2.583920</td>\n",
       "      <td>2.948714</td>\n",
       "      <td>3.112856</td>\n",
       "      <td>3.299712</td>\n",
       "      <td>6.040656</td>\n",
       "      <td>...</td>\n",
       "      <td>22.736962</td>\n",
       "      <td>22.842219</td>\n",
       "      <td>22.905865</td>\n",
       "      <td>22.971377</td>\n",
       "      <td>22.982869</td>\n",
       "      <td>23.614314</td>\n",
       "      <td>23.650248</td>\n",
       "      <td>23.807894</td>\n",
       "      <td>24.425525</td>\n",
       "      <td>25.271358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28602</th>\n",
       "      <td>9570</td>\n",
       "      <td>1.052182</td>\n",
       "      <td>1.066127</td>\n",
       "      <td>1.805688</td>\n",
       "      <td>1.824387</td>\n",
       "      <td>1.864275</td>\n",
       "      <td>2.420648</td>\n",
       "      <td>2.431845</td>\n",
       "      <td>2.757334</td>\n",
       "      <td>3.235232</td>\n",
       "      <td>...</td>\n",
       "      <td>35.510581</td>\n",
       "      <td>35.700678</td>\n",
       "      <td>37.062503</td>\n",
       "      <td>37.789828</td>\n",
       "      <td>38.569837</td>\n",
       "      <td>39.213227</td>\n",
       "      <td>41.504263</td>\n",
       "      <td>41.963118</td>\n",
       "      <td>41.983141</td>\n",
       "      <td>42.038623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28603</th>\n",
       "      <td>9836</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.307083</td>\n",
       "      <td>0.311297</td>\n",
       "      <td>0.426553</td>\n",
       "      <td>0.449229</td>\n",
       "      <td>0.453311</td>\n",
       "      <td>1.199124</td>\n",
       "      <td>...</td>\n",
       "      <td>17.048710</td>\n",
       "      <td>17.993623</td>\n",
       "      <td>18.675683</td>\n",
       "      <td>18.827421</td>\n",
       "      <td>18.847187</td>\n",
       "      <td>18.923304</td>\n",
       "      <td>18.929989</td>\n",
       "      <td>19.166302</td>\n",
       "      <td>19.362858</td>\n",
       "      <td>19.370905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       neuron_id  timestamp_0  timestamp_1  timestamp_2  timestamp_3  \\\n",
       "ID                                                                     \n",
       "28599       9456     1.501446     1.935893     2.100466     2.144410   \n",
       "28600      10064     0.059309     0.116247     0.163038     0.262012   \n",
       "28601      10045     0.563164     1.563625     1.677879     1.881264   \n",
       "28602       9570     1.052182     1.066127     1.805688     1.824387   \n",
       "28603       9836     0.004843     0.026412     0.033590     0.307083   \n",
       "\n",
       "       timestamp_4  timestamp_5  timestamp_6  timestamp_7  timestamp_8  ...  \\\n",
       "ID                                                                      ...   \n",
       "28599     2.259503     2.269867     2.292989     2.346420     2.724702  ...   \n",
       "28600     0.301379     1.813054     2.068066     2.168285     2.232430  ...   \n",
       "28601     2.583920     2.948714     3.112856     3.299712     6.040656  ...   \n",
       "28602     1.864275     2.420648     2.431845     2.757334     3.235232  ...   \n",
       "28603     0.311297     0.426553     0.449229     0.453311     1.199124  ...   \n",
       "\n",
       "       timestamp_40  timestamp_41  timestamp_42  timestamp_43  timestamp_44  \\\n",
       "ID                                                                            \n",
       "28599     20.970412     20.984293     20.997030     21.016212     21.039446   \n",
       "28600     21.518761     22.137357     22.504569     23.102718     23.155953   \n",
       "28601     22.736962     22.842219     22.905865     22.971377     22.982869   \n",
       "28602     35.510581     35.700678     37.062503     37.789828     38.569837   \n",
       "28603     17.048710     17.993623     18.675683     18.827421     18.847187   \n",
       "\n",
       "       timestamp_45  timestamp_46  timestamp_47  timestamp_48  timestamp_49  \n",
       "ID                                                                           \n",
       "28599     21.044450     21.277555     21.723172     22.037007     22.061580  \n",
       "28600     23.254136     23.302653     23.480564     23.539625     23.585673  \n",
       "28601     23.614314     23.650248     23.807894     24.425525     25.271358  \n",
       "28602     39.213227     41.504263     41.963118     41.983141     42.038623  \n",
       "28603     18.923304     18.929989     19.166302     19.362858     19.370905  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy.head()\n",
    "dfx_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same number of samples, all good.\n"
     ]
    }
   ],
   "source": [
    "if dfy.shape[0] == dfx.shape[0]:\n",
    "    print(\"Same number of samples, all good.\")\n",
    "else:\n",
    "    print(\"Different number of samples, problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sanity check:** diff etat1/etat2, neuron_id usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DiffÃ©rence entre le nombre d'etats 1 et d'etats 0.\n",
    "dfy.TARGET.value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 neuron_ids in common between the train and test sets.\n"
     ]
    }
   ],
   "source": [
    "# Should we keep the neuron_id col ?\n",
    "xtest_uniques = dfx_test.neuron_id.unique()\n",
    "x_uniques = dfx.neuron_id.unique()\n",
    "diff = [x for x in x_uniques if x in xtest_uniques]\n",
    "print(\"There are {} neuron_ids in common between the train and test sets.\".format(len(diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Balance dataset:** Under-sample class2 to have same number of samples in both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET SEED pour reproducibilitÃ©\n",
    "\n",
    "def undersample(X, y):\n",
    "    \"\"\" Return balanced training dataset obtained by undersampling class 2. \"\"\"\n",
    "    # Extract class2 indices from Y\n",
    "    y_class1_ix = np.where(y == 1)[0]\n",
    "    y_class2_ix = np.where(y == 0)[0]\n",
    "    \n",
    "    # Under-sample class2 to get balanced classes\n",
    "    y_class2_ix_undersampled = np.random.choice(y_class2_ix, len(y_class1_ix))\n",
    "\n",
    "    # Concatenate the undersampled_class2_array and the class1_array\n",
    "    balanced_ix = np.concatenate((y_class1_ix, y_class2_ix_undersampled), axis=0)\n",
    "    np.random.shuffle(balanced_ix)\n",
    "    \n",
    "    # Create X_train dataset (Keras will do the val split)\n",
    "    X_train = X[balanced_ix]\n",
    "    y_train = y[balanced_ix]\n",
    "    \n",
    "    \"\"\" DEPRECATED:\n",
    "    # Create **UNOFFICIAL** X_test containing only 0s.\n",
    "    balanced_ix_test = np.in1d(range(X.shape[0]), balanced_ix)\n",
    "    X_test = X[~balanced_ix_test]\n",
    "    y_test = y[~balanced_ix_test]\"\"\"\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Extract features:** Use tsfresh to perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>level_1</th>\n",
       "      <th>spike_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>timestamp_0</td>\n",
       "      <td>0.166262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>timestamp_1</td>\n",
       "      <td>0.170520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>timestamp_2</td>\n",
       "      <td>0.176371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>timestamp_3</td>\n",
       "      <td>0.197565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>timestamp_4</td>\n",
       "      <td>0.212814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      level_1  spike_time\n",
       "0   0  timestamp_0    0.166262\n",
       "1   0  timestamp_1    0.170520\n",
       "2   0  timestamp_2    0.176371\n",
       "3   0  timestamp_3    0.197565\n",
       "4   0  timestamp_4    0.212814"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WIP !\n",
    "dfx = pd.DataFrame(dfx.stack(), columns=['spike_time'])\n",
    "dfx = dfx.reset_index()\n",
    "extracted_features = extract_features(dfx, column_id=\"ID\", column_value=\"spike_time\", column_sort=\"level_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Create Xtrain ytrain:** numpy array from df, with dimensions *(sample_nb, timestep_nb, feature_nb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dfx, dfy, exclude_neuron_id=True, balancing=\"undersample\", normalise=False, differencing=False, get_tsfresh=False, get_ISI_SPIKE=False, testing=False, **extras):    \n",
    "   \n",
    "    if exclude_neuron_id:\n",
    "        # X: Exclude neuron_id column from array\n",
    "        dfx = dfx.drop(columns=['neuron_id'])\n",
    "\n",
    "    if get_tsfresh:\n",
    "        \n",
    "    \n",
    "    X = dfx.values\n",
    "    \n",
    "    X = X[..., np.newaxis]\n",
    "    y = np.reshape(dfy.values, (dfy.values.shape[0],))\n",
    "       \n",
    "    if balancing == \"undersample\" and not testing:\n",
    "        X, y = undersample(X, y)\n",
    "        \n",
    "    if normalise:\n",
    "        pass\n",
    "    \n",
    "    # Convert from timeseries to interval\n",
    "    if differencing:\n",
    "        X[:,1:] -= X[:,:-1]\n",
    " \n",
    "    if get_ISI_SPIKE:\n",
    "        pass\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Deprecated:** Concatenate neuron_id to every timestep of a sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntimesteps_arr = dfx.iloc[:,1:].values\\ntimesteps_arr = timesteps_arr[..., np.newaxis]\\ntimesteps_arr.shape\\n\\nneuron_arr = dfx.iloc[:,0].values\\nneuron_arr.shape\\n\\nneuron_arr = np.broadcast_to(neuron_arr[:,None,None], timesteps_arr.shape)\\nfinal_arr = np.concatenate((timesteps_arr,neuron_arr), axis=2)\\nfinal_arr.shape\\n'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : Make a 3d numpy array from our pandas df\n",
    "# Shape = [samples, timestamps, features]\n",
    "\"\"\"\n",
    "timesteps_arr = dfx.iloc[:,1:].values\n",
    "timesteps_arr = timesteps_arr[..., np.newaxis]\n",
    "timesteps_arr.shape\n",
    "\n",
    "neuron_arr = dfx.iloc[:,0].values\n",
    "neuron_arr.shape\n",
    "\n",
    "neuron_arr = np.broadcast_to(neuron_arr[:,None,None], timesteps_arr.shape)\n",
    "final_arr = np.concatenate((timesteps_arr,neuron_arr), axis=2)\n",
    "final_arr.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Arxiv: [Neural activity classification with machine learning models trained oninterspike interval series data](https://arxiv.org/pdf/1810.03855.pdf) => PCA and KNN\n",
    "* Github: [PySpike: Python library to analyze spike Train](https://github.com/mariomulansky/PySpike) => Obscure mathematical measurements between spike trains\n",
    "* Profil: [Prof expert en spike train analysis](http://xtof.perso.math.cnrs.fr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'name': \"LSTM_Differencing\",\n",
    "    'exclude_neuron_id': True,\n",
    "    'balancing': \"undersample\",\n",
    "    'normalise': False,\n",
    "    'differencing': True,\n",
    "    'get_tsfresh': False,\n",
    "    'get_ISI_SPIKE': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6116, 50, 1) (11969, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = getData(dfx, dfy, **params)\n",
    "X_test, _ = getData(dfx_test, dfy, testing=True, **params)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep-Learning 1: blunt RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Create and train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,961\n",
      "Trainable params: 16,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timestamp_nb = 50\n",
    "feature_nb = 1\n",
    "params['cell_nb'] = 64\n",
    "\n",
    "input_shape = (timestamp_nb, feature_nb)\n",
    "x = input_tensor = Input(input_shape)\n",
    "x = LSTM(params['cell_nb'], return_sequences=False)(x)\n",
    "x = output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5504 samples, validate on 612 samples\n",
      "Epoch 1/3\n",
      "5504/5504 [==============================] - 23s 4ms/step - loss: 0.2435 - acc: 0.5705 - val_loss: 0.2510 - val_acc: 0.6144\n",
      "Epoch 2/3\n",
      "5504/5504 [==============================] - 18s 3ms/step - loss: 0.2365 - acc: 0.6065 - val_loss: 0.2369 - val_acc: 0.6095\n",
      "Epoch 3/3\n",
      "5504/5504 [==============================] - 18s 3ms/step - loss: 0.2313 - acc: 0.6215 - val_loss: 0.2322 - val_acc: 0.6144\n"
     ]
    }
   ],
   "source": [
    "model.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_params = [\n",
    "    ('batch_size', history.params['batch_size']),\n",
    "    ('epochs', history.params['epochs']),\n",
    "    ('samples', history.params['samples']),\n",
    "    ('val_acc', history.history['val_acc'][-1])\n",
    "    ]\n",
    "\n",
    "for param in history_params:\n",
    "    params[param[0]] = param[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11969, 50, 1)\n",
      "(11969,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16635</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16636</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16637</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16638</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TARGET\n",
       "ID           \n",
       "16635       0\n",
       "16636       1\n",
       "16637       1\n",
       "16638       0\n",
       "16639       0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X_test):\n",
    "    # Predict on custom X_test\n",
    "    print (X_test.shape)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.reshape(y_pred, (y_pred.shape[0],))\n",
    "    print (y_pred.shape)\n",
    "    # Convert sigmoid output to 0s and 1s\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "  \n",
    "    # Format .csv in ENS style\n",
    "    dfy_pred = pd.DataFrame(data=y_pred, columns=[\"TARGET\"], dtype=int)\n",
    "    dfy_pred.index.name = \"ID\"\n",
    "    dfy_pred.index += 16635\n",
    "    return dfy_pred\n",
    "\n",
    "dfy_pred = predict(X_test)\n",
    "dfy_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6116, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain-knowledge 1: Benchmark = differencing + tsfresh feature engineering + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain-knowledge 2: KNN with SPIKE- and ISI- synchronization distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/0606200928'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def saveExp(dfy_pred, model, params):\n",
    "    \"\"\" Create directory in which to save predictions, experiment parameters and model object. \"\"\"\n",
    "\n",
    "    directory = \"../experiments/{}\".format(datetime.datetime.now().strftime(\"%m%d%H%M%S\"))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    dfy_pred.to_csv(directory + '/y_pred.csv', sep=',')\n",
    "    \n",
    "    model.save(directory + '/model.h5')\n",
    "    \n",
    "    columns = []\n",
    "    values = []\n",
    "    for k, v in params.items():\n",
    "        columns.append(k)\n",
    "        values.append(v)\n",
    "    params_df = pd.DataFrame(data=[values], columns=columns)\n",
    "    params_df.to_csv(directory + '/params.csv', sep=';')\n",
    "    return directory\n",
    "\n",
    "# Save model\n",
    "saveExp(dfy_pred, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
